{"title":"All you need to know about CVAT","markdown":{"yaml":{"toc":true,"layout":"post","description":"Get to know Computer vision annotation tool.","categories":["annotation"],"title":"All you need to know about CVAT"},"headingText":"Introduction","containsRefs":false,"markdown":"\n\nOnce you start your journey into data science, you quickly learn that as part of your job you are spending more time with data than models. Data and labels go hand in hand and hence, I will be sharing what you need to know before you decide to use [CVAT](https://cvat.org) as your image/video annotation tool. Let's start with the easier bit i.e. complete name of tool - Computer Vision Annotation Tool \n\n\n## Ease of Setup\n\nA treat awaits in this section if you have worked with [docker compose](https://docs.docker.com/compose/) before, CVAT is very easy to setup as the source code contains necessary docker compose files which makes complete setup a breeze in your local. Repo also features an instruction documentation which is comprehensively written and covers every line of code that needs to be executed in order to get the tool running.  \n\nComplete setup is nicely segregated into docker-compose files with docker apps named cvat,cvat_ui, cvat_db. \nThere are two ways to go ahead with setting up the tool, the easier way of deploying it in a VM and a little longer way on Kubernetes. A VM with enough firepower to run an instance of Postgres, Django backend and a react app to support the number of users that you expect to access the tool simultaneously should be alright. An example: I was able to support 200+ users(some of them were automated scripts) in a single VM with the analytics component running using a Standard D5 v2 (16 vcpus, 56 GiB memory) Azure VM. The power of your VM needs to be proportionately increased if you wish to use the additional components like deep learning model based auto labelling. \nIf you choose to deploy the tool in Kubernetes, you could benefit from the auto-scaling functionality for each app inside CVAT. Kubernetes YAML files are not available as part of source code and hence you might need to create them yourself. I recommend [Kompose](https://kompose.io) to create Kubrnetes YAML from docker compose files. Scalability is an important aspect while considering a tool for production deployment. In order to make sure that the tool works for foreseeable growth in number of users. App can be scaled easily since everything is nicely wrapped into docker containers. \n\n## Ease of Usage\n\nThe application's desktop UI although not fancy, is very feature rich and achieves the goal of labeling images and videos with ease.There's a long list of keyboard shortcuts supported and you don't necessarily need to remember every shortcut, simply pick and choose which help you speed up. I found the shortcut to create poly shapes and rectangles during labelling as very useful. Keyboard shortcuts combined with the feature rich app make labelling task slick and smooth. The application also features a task assignment and task process flow using which larger teams can collaborate by assigning tasks to a specific user and updating the current status of task for others to see. CVAT is developed considering the desktop based user interface, which means we need to keep expectations lower while trying to use it on mobile or tablets. You can try the app online right now by navigating to [cvat.org](https://cvat.org)\nCVAT also features a command line interface which enables you to perform simple CRUD operations on task.\n\n## Data Extraction/ Upload\n\nA Django app in backend and react UI as frontend, CVAT is quite covered with options to upload data via UI or CLI. App works on a unique task based system, each upload is created as a task in the system. The task can then be further assigned to different users for labelling, quality check, etc. When using the UI to upload data, you don't need to worry about label formatting because the app takes care of it. CLI based upload requires data to be structured in specific formats before it can be processed. I recommend CLI to perform automated scripts based data upload and UI when actual human is performing the uplaod and labelling task. \n\nExtraction of data is a very important step which will have to be performed by every team on regular basis. CVAT supports extraction of data in a format by both interfaces i.e. UI and CLI. A user can go to a task and there's option to extract the data in various supported formats. when trying to extract multiple data points or tasks in CVAT, UI based extraction might seem time consuming . CLI comes to rescue here, extraction of data in any supported format is super simple using CLI. An important thing to note here is CVAT currently doesn't support bulk extraction or upload of data using UI.\n\nThe dev team also mentiond about datumaro dataset framework which can be used to transform, merge, extract multiple datasets from CVAT. I was not able to get it working and therefore no comments on that. \n\n## Annotations Format Supported\n\nI am borrowing a table available in CVAT documentation to show the formats supported. It supports all major community defined data label formats. The labels covers the spectrum of classification, obejct detection and segmentation tasks in computer vision.\n\n\n| Annotation format                                                                          | Import | Export |\n| ------------------------------------------------------------------------------------------ | ------ | ------ |\n| [CVAT for images](https://github.com/jainds/cvat/blob/develop/cvat/apps/documentation/xml_format.md#annotation)                        | X      | X      |\n| [CVAT for a video](https://github.com/jainds/cvat/blob/develop/cvat/apps/documentation/xml_format.md#interpolation)                    | X      | X      |\n| [Datumaro](https://github.com/jainds/cvat/blob/develop/datumaro/README.md)                                                             |        | X      |\n| [PASCAL VOC](http://host.robots.ox.ac.uk/pascal/VOC/)                                      | X      | X      |\n| Segmentation masks from [PASCAL VOC](http://host.robots.ox.ac.uk/pascal/VOC/)              | X      | X      |\n| [YOLO](https://pjreddie.com/darknet/yolo/)                                                 | X      | X      |\n| [MS COCO Object Detection](http://cocodataset.org/#format-data)                            | X      | X      |\n| [TFrecord](https://www.tensorflow.org/tutorials/load_data/tf_records)                      | X      | X      |\n| [MOT](https://motchallenge.net/)                                                           | X      | X      |\n| [LabelMe 3.0](http://labelme.csail.mit.edu/Release3.0)                                     | X      | X      |\n\n## Backup and Restore\n\nAll images/videos uploaded are stored in docker volume cvat_data and the respective label data is stored in postgres. Postgres data is stored in docker volume cvat_db. In order to backup the complete app data, you can simply create volume backup for these two volumes in form of .tar files. \nConfiguring the said docker volumes to a persistent storage like S3 or azure blob would enable you to setup automated cloud backup for these volumes. \nRestoration is as simple as backup by using docker commands. \n\n## Community\n\nCVAT community is available on [GitHub](https://github.com/opencv/cvat) and [Gitter](https://gitter.im/opencv-cvat/public). I have personally found them responding faster on gitter compared to raising issues on github. \n\n","srcMarkdownNoYaml":"\n## Introduction\n\nOnce you start your journey into data science, you quickly learn that as part of your job you are spending more time with data than models. Data and labels go hand in hand and hence, I will be sharing what you need to know before you decide to use [CVAT](https://cvat.org) as your image/video annotation tool. Let's start with the easier bit i.e. complete name of tool - Computer Vision Annotation Tool \n\n\n## Ease of Setup\n\nA treat awaits in this section if you have worked with [docker compose](https://docs.docker.com/compose/) before, CVAT is very easy to setup as the source code contains necessary docker compose files which makes complete setup a breeze in your local. Repo also features an instruction documentation which is comprehensively written and covers every line of code that needs to be executed in order to get the tool running.  \n\nComplete setup is nicely segregated into docker-compose files with docker apps named cvat,cvat_ui, cvat_db. \nThere are two ways to go ahead with setting up the tool, the easier way of deploying it in a VM and a little longer way on Kubernetes. A VM with enough firepower to run an instance of Postgres, Django backend and a react app to support the number of users that you expect to access the tool simultaneously should be alright. An example: I was able to support 200+ users(some of them were automated scripts) in a single VM with the analytics component running using a Standard D5 v2 (16 vcpus, 56 GiB memory) Azure VM. The power of your VM needs to be proportionately increased if you wish to use the additional components like deep learning model based auto labelling. \nIf you choose to deploy the tool in Kubernetes, you could benefit from the auto-scaling functionality for each app inside CVAT. Kubernetes YAML files are not available as part of source code and hence you might need to create them yourself. I recommend [Kompose](https://kompose.io) to create Kubrnetes YAML from docker compose files. Scalability is an important aspect while considering a tool for production deployment. In order to make sure that the tool works for foreseeable growth in number of users. App can be scaled easily since everything is nicely wrapped into docker containers. \n\n## Ease of Usage\n\nThe application's desktop UI although not fancy, is very feature rich and achieves the goal of labeling images and videos with ease.There's a long list of keyboard shortcuts supported and you don't necessarily need to remember every shortcut, simply pick and choose which help you speed up. I found the shortcut to create poly shapes and rectangles during labelling as very useful. Keyboard shortcuts combined with the feature rich app make labelling task slick and smooth. The application also features a task assignment and task process flow using which larger teams can collaborate by assigning tasks to a specific user and updating the current status of task for others to see. CVAT is developed considering the desktop based user interface, which means we need to keep expectations lower while trying to use it on mobile or tablets. You can try the app online right now by navigating to [cvat.org](https://cvat.org)\nCVAT also features a command line interface which enables you to perform simple CRUD operations on task.\n\n## Data Extraction/ Upload\n\nA Django app in backend and react UI as frontend, CVAT is quite covered with options to upload data via UI or CLI. App works on a unique task based system, each upload is created as a task in the system. The task can then be further assigned to different users for labelling, quality check, etc. When using the UI to upload data, you don't need to worry about label formatting because the app takes care of it. CLI based upload requires data to be structured in specific formats before it can be processed. I recommend CLI to perform automated scripts based data upload and UI when actual human is performing the uplaod and labelling task. \n\nExtraction of data is a very important step which will have to be performed by every team on regular basis. CVAT supports extraction of data in a format by both interfaces i.e. UI and CLI. A user can go to a task and there's option to extract the data in various supported formats. when trying to extract multiple data points or tasks in CVAT, UI based extraction might seem time consuming . CLI comes to rescue here, extraction of data in any supported format is super simple using CLI. An important thing to note here is CVAT currently doesn't support bulk extraction or upload of data using UI.\n\nThe dev team also mentiond about datumaro dataset framework which can be used to transform, merge, extract multiple datasets from CVAT. I was not able to get it working and therefore no comments on that. \n\n## Annotations Format Supported\n\nI am borrowing a table available in CVAT documentation to show the formats supported. It supports all major community defined data label formats. The labels covers the spectrum of classification, obejct detection and segmentation tasks in computer vision.\n\n\n| Annotation format                                                                          | Import | Export |\n| ------------------------------------------------------------------------------------------ | ------ | ------ |\n| [CVAT for images](https://github.com/jainds/cvat/blob/develop/cvat/apps/documentation/xml_format.md#annotation)                        | X      | X      |\n| [CVAT for a video](https://github.com/jainds/cvat/blob/develop/cvat/apps/documentation/xml_format.md#interpolation)                    | X      | X      |\n| [Datumaro](https://github.com/jainds/cvat/blob/develop/datumaro/README.md)                                                             |        | X      |\n| [PASCAL VOC](http://host.robots.ox.ac.uk/pascal/VOC/)                                      | X      | X      |\n| Segmentation masks from [PASCAL VOC](http://host.robots.ox.ac.uk/pascal/VOC/)              | X      | X      |\n| [YOLO](https://pjreddie.com/darknet/yolo/)                                                 | X      | X      |\n| [MS COCO Object Detection](http://cocodataset.org/#format-data)                            | X      | X      |\n| [TFrecord](https://www.tensorflow.org/tutorials/load_data/tf_records)                      | X      | X      |\n| [MOT](https://motchallenge.net/)                                                           | X      | X      |\n| [LabelMe 3.0](http://labelme.csail.mit.edu/Release3.0)                                     | X      | X      |\n\n## Backup and Restore\n\nAll images/videos uploaded are stored in docker volume cvat_data and the respective label data is stored in postgres. Postgres data is stored in docker volume cvat_db. In order to backup the complete app data, you can simply create volume backup for these two volumes in form of .tar files. \nConfiguring the said docker volumes to a persistent storage like S3 or azure blob would enable you to setup automated cloud backup for these volumes. \nRestoration is as simple as backup by using docker commands. \n\n## Community\n\nCVAT community is available on [GitHub](https://github.com/opencv/cvat) and [Gitter](https://gitter.im/opencv-cvat/public). I have personally found them responding faster on gitter compared to raising issues on github. \n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../styles.css"],"toc":true,"output-file":"2020-07-11-CVAT-All-you-need-to-know.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.6.42","theme":["cosmo","brand"],"title-block-banner":true,"layout":"post","description":"Get to know Computer vision annotation tool.","categories":["annotation"],"title":"All you need to know about CVAT"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}