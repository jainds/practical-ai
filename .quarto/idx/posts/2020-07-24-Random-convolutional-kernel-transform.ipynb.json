{"title":"\"Random Convolutional Kernel Transform\"","markdown":{"yaml":{"title":"\"Random Convolutional Kernel Transform\""},"headingText":"Introduction","containsRefs":false,"markdown":"\n\n\n\n> \"Understanding the ROCKET paper step by step with an example comparing results with LSTM\"\n\n- toc: true\n- branch: master\n- badges: true\n- comments: true\n- categories: [research-paper, time-series, classification]\n- image: images/Rocket-mean-acuracy-on-bakeoff-datasets.png\n- hide: false\n- search_exclude: false\n\n\n\n\n\n\n  ***ROCKET: Exceptionally fast and accurate time series classification using random convolutional kernels***  is a research paper published in October 2019 by Angus Dempster, François Petitjean, Geoffrey I. Webb. The paper presents a unique methodology to transform time series data using convolutional kernels to improve classification accuracy. This paper is unique in learning from the recent success of convolutional neural networks and transferring it on time-series datasets. \n\nThe link to download the paper from arxiv - [Paper](https://arxiv.org/pdf/1910.13051)\n\n\n\n## Time Series data\n\nTime series data is defined as a set of data points containing details about different points in time. Generally, time-series data contains data points sampled/observed at an equal interval of time. Time series classification is task of identifying patterns and signals in the data in relation to respective classes. \n\nThe proposal is features generated by the convolution of randomly generated kernels on time series data results in faster and better time series classifiers. We will go into more detail of this proposal and understand how the methodology proposed by them helps to improve the accuracy. \n\n## Kernels\n\nKernels in simple terms is a small matrix used to modify the images. Let's try to understand kernels using an example: \n\nhere is a 3 x 3 kernel used to sharpen images: \n\n$\\begin{bmatrix} 0 & -1 & 0 \\\\ -1 & 5 & -1 \\\\ 0 & -1 & 0  \\end{bmatrix}$\n\nTo sharpen an image using the above kernel, we need to perform a dot product of each pixel in the image with the kernel matrix. The resulting image would then be a sharpened version of the original image. Observe the gif below to see a live version of the kernel dot product in motion. \n\nFollowing is an example from setosa.io site to demonstrate how kernels can be used to make desirable changes to an image. \n\n![](images/setosa-kernel-image.png \"credit: setosa.io/ev/image-kernels/\")\n\n### 5 parameters of kernels\n\nA kernel has 5 different parameter using which it can be configured. \n\n| Parameter      | Description | Value logic |\n| ----------- | ----------- | --------- |\n| Bias      | Bias is added to the result of the convolution operation between input time series and weights of the given kernel | Bias is sampled from a uniform distribution, b ∼ U(−1,1) |\n| Size(Length)   | Size defines the number of rows and columns a kernel has. The above example has a size of 3 rows and 3 columns | Length is selected randomly from {7,9,11} with equal probability, making kernels considerably shorter than input time series in most cases |\n| Weights | The values that make up the kernel matrix are weights  | The weights are sampled from a normal distribution, ∀w ∈ W, w ∼ N(0,1), and are mean-centered after being set, ω = W − W. As such, most weights are relatively small, but can take on larger magnitudes |\n| Dilation | Dilation spreads a kernel over the input such that with dilation of value two, weights in a kernel are convolved with every second element of input time series | Dilation is sampled on an exponential scale d = ⌊2x⌋,x ∼ U(0,A), input −1 where A = log2 kernel −1 |\n| Padding | Padding involves appending values(typically zero) to the start and end of input time series such that the middleweight of a kernel aligns with the first value of input time series at the start of convolution| When each kernel is generated, a decision is made (at random, with equal probability) whether or not padding will be used when applying the kernel| \n\n## Features generated by Rocket kernel\n\nRocket computes two aggregate features from each kernel and feature convolution. The two features are created using the well-known methodology global/average max pooling and a unique methodology positive proportion value (ppv). \n\n### Max-pooling\n\nGlobal max-pooling is essentially picking the maximum value from the result of convolution and max pooling is picking the maximum value within a pool size. \nAssuming that the output of convolution is 0,1,2,2,5,1,2, global max pooling outputs 5, whereas ordinary max pooling  with pool size equals to 3 outputs 2,2,5,5,5\n\n### Proportion of positive values\n\nLet's try to understand using the author's own words to describe ppv. \n\n> ppv directly captures the proportion of the input which matches a given pattern, i.e., for which the output of the convolution operation is positive. The ppv works in conjunction with the bias term. The bias term acts as a kind of ‘threshold’ for ppv. A positive bias value means that ppv captures the proportion of the input reflecting even ‘weak’ matches between the input and a given pattern, while a negative bias value means that ppv only captures the proportion of the input reflecting ‘strong’ matches between the input and the given pattern.\n\n## Rocket usage\n\nNow that we understand what kernels are and how rocket generates two outputs by convolution of kernel and input vector, let's understand how to use it.\n\nThe time-series data needs to be provided as input into the rocket transform method, the value for the number of kernels (i.e. k) is set at 10,000 by default. This means that for each one of the input features we get 20,000 features as output from rocket transform. \n\nThe transformed feature table can now we used as input data for any classification algorithm, authors advise linear algorithms like ridge regression classifier or logistic regression. \n\n\n## Rocket v/s others\n\nRocket's approach of creating a large number of random kernels and generating two features from each kernel is unique. Rocket distinguishes itself based on various other factors which we will discuss below. \n\n### Rocket v/s neural nets\n\n1. Rocket doesn’t use a hidden layer or any non-linearities\n2. Features produced by Rocket are independent of each other\n3. Rocket works with any kind of classifier\n\n### Rocket v/s CNN\n\n1. Rocket uses a very large number of kernels\n2. In CNN, a group of kernels tend to share the same size, dilation and padding. Rocket has all 5 parameters randomized.\n3. In CNN, Dilation increases exponentially with depth; Rocket has random dilation values\n4. CNNs only have average/max pooling. Rocket has a unique pooling called as ppv which has proven to provide much better classification accuracy on time series. \n\n\n## Rocket performance\n\nThe authors provide detailed information about the classification accuracy and time taken to train the model. I am discussing the results from bakeoff datasets in this article and you will be able to find results from various additional datasets in the paper. \n\n### Accuracy\n\nRank is calculated by taking a mean value of classification accuracy across all the 85 datasets in bakeoff datasets. \n\nIt is clear that the model trained using features derived using rocket is faring better compared to other models on average among all the datasets in bake-off datasets. Please note that the dark horizontal line connecting the rank position of two models depict that the results from two models are not statistically insignificant.\n\n![](https://github.com/jainds/practical-ai/blob/master/_notebooks/images/Rocket-mean-acuracy-on-bakeoff-datasets.png?raw=1)\n\n### Time taken to train\n\n| Architecture | Largest dataset(ElectricDevices, with 8,926 training examples) | Longest time series(HandOutlines, with time series of length 2,709) | \n| ---------- | -------- | ---------| \n| ROCKET | 6 minutes 33 seconds | 4 minutes 18 seconds | \n| MrSEQL | 31 minutes | 1 hour 55 minutes |\n| cBOSS | 3 hours 6 minutes  | 42 minutes |\n| Proximity Forest | 1 hour 35 minutes| 3 days |\n| TS-CHIEF | 2 hours 24 minutes| 4 days |\n| Inception Time (on GPU) | 7 hours 46 minutes | 8 hours 10 minutes |\n\n\n## Example\n\nIn the below examples, we are going to try and train a Human activity recognizer time series classifier.\nI am using two nice repo by Guillaume Chevalier showcasing [LSTM model on Human activity recognizer](https://github.com/jainds/LSTM-Human-Activity-Recognition ) with a classification accuracy of 91% and by [Thanatchon](https://github.com/thanatchon36/Rocket_vs_LSTM-Human-Activity-Recognition) . Let's see how much accuracy can be achieved by using rocket transforms. \n\nWe will be using sktime implementation of rocket in this example\n\n### Install libraries & import Statements\n\n\n\n### Download dataset and extract \n\n### Defining Train test data\n\n### Preparing dataset \n\n### Rocket Model\n\n### Accuracy \n\n## Conclusion\n\nWe were able to improve upon accuracy achieved by LSTM model by a very simple implementation using Rocket. LSTM had scored 91% and using Rocket + Ridge Regression classifier the accuracy jumped to 93%. The performance gain achieved becomes sweeter when you compare the time required to code and train, which was very small compared for rocket in comparison to LSTM in our case. \nThe Rocket methodology is an innovative, simple and fresh technique that attracted my attention to this research paper. \n","srcMarkdownNoYaml":"\n\n\n\n> \"Understanding the ROCKET paper step by step with an example comparing results with LSTM\"\n\n- toc: true\n- branch: master\n- badges: true\n- comments: true\n- categories: [research-paper, time-series, classification]\n- image: images/Rocket-mean-acuracy-on-bakeoff-datasets.png\n- hide: false\n- search_exclude: false\n\n\n\n\n\n## Introduction\n\n  ***ROCKET: Exceptionally fast and accurate time series classification using random convolutional kernels***  is a research paper published in October 2019 by Angus Dempster, François Petitjean, Geoffrey I. Webb. The paper presents a unique methodology to transform time series data using convolutional kernels to improve classification accuracy. This paper is unique in learning from the recent success of convolutional neural networks and transferring it on time-series datasets. \n\nThe link to download the paper from arxiv - [Paper](https://arxiv.org/pdf/1910.13051)\n\n\n\n## Time Series data\n\nTime series data is defined as a set of data points containing details about different points in time. Generally, time-series data contains data points sampled/observed at an equal interval of time. Time series classification is task of identifying patterns and signals in the data in relation to respective classes. \n\nThe proposal is features generated by the convolution of randomly generated kernels on time series data results in faster and better time series classifiers. We will go into more detail of this proposal and understand how the methodology proposed by them helps to improve the accuracy. \n\n## Kernels\n\nKernels in simple terms is a small matrix used to modify the images. Let's try to understand kernels using an example: \n\nhere is a 3 x 3 kernel used to sharpen images: \n\n$\\begin{bmatrix} 0 & -1 & 0 \\\\ -1 & 5 & -1 \\\\ 0 & -1 & 0  \\end{bmatrix}$\n\nTo sharpen an image using the above kernel, we need to perform a dot product of each pixel in the image with the kernel matrix. The resulting image would then be a sharpened version of the original image. Observe the gif below to see a live version of the kernel dot product in motion. \n\nFollowing is an example from setosa.io site to demonstrate how kernels can be used to make desirable changes to an image. \n\n![](images/setosa-kernel-image.png \"credit: setosa.io/ev/image-kernels/\")\n\n### 5 parameters of kernels\n\nA kernel has 5 different parameter using which it can be configured. \n\n| Parameter      | Description | Value logic |\n| ----------- | ----------- | --------- |\n| Bias      | Bias is added to the result of the convolution operation between input time series and weights of the given kernel | Bias is sampled from a uniform distribution, b ∼ U(−1,1) |\n| Size(Length)   | Size defines the number of rows and columns a kernel has. The above example has a size of 3 rows and 3 columns | Length is selected randomly from {7,9,11} with equal probability, making kernels considerably shorter than input time series in most cases |\n| Weights | The values that make up the kernel matrix are weights  | The weights are sampled from a normal distribution, ∀w ∈ W, w ∼ N(0,1), and are mean-centered after being set, ω = W − W. As such, most weights are relatively small, but can take on larger magnitudes |\n| Dilation | Dilation spreads a kernel over the input such that with dilation of value two, weights in a kernel are convolved with every second element of input time series | Dilation is sampled on an exponential scale d = ⌊2x⌋,x ∼ U(0,A), input −1 where A = log2 kernel −1 |\n| Padding | Padding involves appending values(typically zero) to the start and end of input time series such that the middleweight of a kernel aligns with the first value of input time series at the start of convolution| When each kernel is generated, a decision is made (at random, with equal probability) whether or not padding will be used when applying the kernel| \n\n## Features generated by Rocket kernel\n\nRocket computes two aggregate features from each kernel and feature convolution. The two features are created using the well-known methodology global/average max pooling and a unique methodology positive proportion value (ppv). \n\n### Max-pooling\n\nGlobal max-pooling is essentially picking the maximum value from the result of convolution and max pooling is picking the maximum value within a pool size. \nAssuming that the output of convolution is 0,1,2,2,5,1,2, global max pooling outputs 5, whereas ordinary max pooling  with pool size equals to 3 outputs 2,2,5,5,5\n\n### Proportion of positive values\n\nLet's try to understand using the author's own words to describe ppv. \n\n> ppv directly captures the proportion of the input which matches a given pattern, i.e., for which the output of the convolution operation is positive. The ppv works in conjunction with the bias term. The bias term acts as a kind of ‘threshold’ for ppv. A positive bias value means that ppv captures the proportion of the input reflecting even ‘weak’ matches between the input and a given pattern, while a negative bias value means that ppv only captures the proportion of the input reflecting ‘strong’ matches between the input and the given pattern.\n\n## Rocket usage\n\nNow that we understand what kernels are and how rocket generates two outputs by convolution of kernel and input vector, let's understand how to use it.\n\nThe time-series data needs to be provided as input into the rocket transform method, the value for the number of kernels (i.e. k) is set at 10,000 by default. This means that for each one of the input features we get 20,000 features as output from rocket transform. \n\nThe transformed feature table can now we used as input data for any classification algorithm, authors advise linear algorithms like ridge regression classifier or logistic regression. \n\n\n## Rocket v/s others\n\nRocket's approach of creating a large number of random kernels and generating two features from each kernel is unique. Rocket distinguishes itself based on various other factors which we will discuss below. \n\n### Rocket v/s neural nets\n\n1. Rocket doesn’t use a hidden layer or any non-linearities\n2. Features produced by Rocket are independent of each other\n3. Rocket works with any kind of classifier\n\n### Rocket v/s CNN\n\n1. Rocket uses a very large number of kernels\n2. In CNN, a group of kernels tend to share the same size, dilation and padding. Rocket has all 5 parameters randomized.\n3. In CNN, Dilation increases exponentially with depth; Rocket has random dilation values\n4. CNNs only have average/max pooling. Rocket has a unique pooling called as ppv which has proven to provide much better classification accuracy on time series. \n\n\n## Rocket performance\n\nThe authors provide detailed information about the classification accuracy and time taken to train the model. I am discussing the results from bakeoff datasets in this article and you will be able to find results from various additional datasets in the paper. \n\n### Accuracy\n\nRank is calculated by taking a mean value of classification accuracy across all the 85 datasets in bakeoff datasets. \n\nIt is clear that the model trained using features derived using rocket is faring better compared to other models on average among all the datasets in bake-off datasets. Please note that the dark horizontal line connecting the rank position of two models depict that the results from two models are not statistically insignificant.\n\n![](https://github.com/jainds/practical-ai/blob/master/_notebooks/images/Rocket-mean-acuracy-on-bakeoff-datasets.png?raw=1)\n\n### Time taken to train\n\n| Architecture | Largest dataset(ElectricDevices, with 8,926 training examples) | Longest time series(HandOutlines, with time series of length 2,709) | \n| ---------- | -------- | ---------| \n| ROCKET | 6 minutes 33 seconds | 4 minutes 18 seconds | \n| MrSEQL | 31 minutes | 1 hour 55 minutes |\n| cBOSS | 3 hours 6 minutes  | 42 minutes |\n| Proximity Forest | 1 hour 35 minutes| 3 days |\n| TS-CHIEF | 2 hours 24 minutes| 4 days |\n| Inception Time (on GPU) | 7 hours 46 minutes | 8 hours 10 minutes |\n\n\n## Example\n\nIn the below examples, we are going to try and train a Human activity recognizer time series classifier.\nI am using two nice repo by Guillaume Chevalier showcasing [LSTM model on Human activity recognizer](https://github.com/jainds/LSTM-Human-Activity-Recognition ) with a classification accuracy of 91% and by [Thanatchon](https://github.com/thanatchon36/Rocket_vs_LSTM-Human-Activity-Recognition) . Let's see how much accuracy can be achieved by using rocket transforms. \n\nWe will be using sktime implementation of rocket in this example\n\n### Install libraries & import Statements\n\n\n\n### Download dataset and extract \n\n### Defining Train test data\n\n### Preparing dataset \n\n### Rocket Model\n\n### Accuracy \n\n## Conclusion\n\nWe were able to improve upon accuracy achieved by LSTM model by a very simple implementation using Rocket. LSTM had scored 91% and using Rocket + Ridge Regression classifier the accuracy jumped to 93%. The performance gain achieved becomes sweeter when you compare the time required to code and train, which was very small compared for rocket in comparison to LSTM in our case. \nThe Rocket methodology is an innovative, simple and fresh technique that attracted my attention to this research paper. \n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../styles.css"],"output-file":"2020-07-24-Random-convolutional-kernel-transform.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.6.42","theme":["cosmo","brand"],"title-block-banner":true,"title":"\"Random Convolutional Kernel Transform\""},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}