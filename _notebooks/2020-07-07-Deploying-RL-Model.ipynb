{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Deployment Journey of a Reinforcement Learning Algorithm\"\n",
    "> \"Step by step journey of a reinforcement learning algorithm into production AKS serving millions of simultaneous users\"\n",
    "\n",
    "- toc: true\n",
    "- branch: master\n",
    "- badges: false\n",
    "- comments: true\n",
    "- categories: [deployment]\n",
    "- image: images/deployment-journey-reinforcement-learning.png\n",
    "- hide: false\n",
    "- search_exclude: false\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Our team is working to improve the health and wealth of millions of current customers and acquire more customers in the future. One of the most effective and efficient way to achieve our goal is by getting an app into the millions of people. As it turns out, we already have a wonderful application which is downloaded by more than 3 million users as I write this post.\n",
    "The mobile application has a carousel portion in the bottom half section of the home page where dynamic banners can be rendered. Each banner is utilized as a form of information, communication medium or an application feature. This is the first page that is seen by all users who successfully register and a portion of them clicking on the banner displayed registering their interest. \n",
    "Our team's goal is to increase engagement within the app. The first step was to understand the source of users who were clicking the banners, why are they willing to go into exploring app via banners after registering while others would go on to explore the app via other routes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem statement\n",
    "\n",
    "The goal was to increase user engagement within the app by understanding user’s interest in a variety of banners and then leverage the results across the app.\n",
    "\n",
    "we didn’t have existing data about user interaction with the app neither did we have enough time at hand to perform that activity. We were also looking at an incoming huge inflow of new users expected in near future due to the planned marketing campaigns. We were essentially looking at a cold start problem to improve engagement since, we would know little about the new users and time to market was a very important factor. We were expected to go live within two weeks duration with a solution to make the best out of data available at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "Bayesian bandits with Thomson sampling ticked all boxes as follows:\n",
    "1. It requires no data or less to start with compared to other options\n",
    "2. It will learn incoming users/data and start recommending banners \n",
    "3. Can work with new banners configured as new arms\n",
    "\n",
    "The next phase of the project was also discussed where we agreed to work on building contextual bandits. In this post, I will be talking more about how we used various tools and technology making deployment possible. I will not be talking about how the recommendation algorithm works and the technology stack used to achieve it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/deployment-journey-reinforcement-learning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The build and deployment part of the project was broken down into two technical stages/phases:\n",
    "1. Testing model and documenting results in the pre-prod environment with production data, define the input and the output schema for the model which will be used by the data engineer team to create a streaming pipeline.\n",
    "2. Setup model to consume a live stream of event data, and respond via a REST endpoint with the recommended list of banners for the users\n",
    "\n",
    "The front end of the mobile app is configured for a response time of one second w.r.t to back-end. It meant that the app will try to generate dynamic banners on the user screen based on our recommendations or fall back to static banners if we failed to deliver a response within a second, which added another layer of complexity to the second stage. Our APIs were expected to support a wide range of user load starting from a few hundred requests to millions across the region.\n",
    "\n",
    "We could list the deployment infra into three major components:\n",
    "1. A robust build and deployment pipeline\n",
    "2. Automated performance testing\n",
    "3. Production monitoring and alerting\n",
    "\n",
    "Tools used for the complete setup:\n",
    "1. Jenkins\n",
    "2. Artifactory\n",
    "3. Docker\n",
    "4. Aquasec image scanning\n",
    "5. Fortify static code scan\n",
    "6.. Sonar Nexus open source code scanning\n",
    "7. Kubernetes\n",
    "8. Predator\n",
    "9. Prometheus\n",
    "10. Grafana\n",
    "11. Bitbucket\n",
    "\n",
    "Our application solution is a bunch of docker images which consumes/produces content in Kafka topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 — Fetching code and checking for changes\n",
    "\n",
    "Our pipeline starts at fetching the code from Bitbucket repository. We store code in the folder structure for the 4 different docker images that are to be built. We check whether a file has been changed before initiating build for the files in that folder. The code in the Jenkins pipeline is as below for one of the folders titled ‘generator’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-822414454e3f>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-822414454e3f>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    script{\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#hide_output\n",
    "script{\n",
    "            GIT_RESULT = sh(script: '''git diff --quiet HEAD \"$(git rev-parse @~1)\" -- generator''',\n",
    "                returnStatus: true\n",
    "                )\n",
    "                echo \"GIT RESULT -- ${GIT_RESULT} -- ${params.branchname}\"\n",
    "              }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Fortify\n",
    "\n",
    "Next step is to run complete code static security scanning by Fortify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide_output\n",
    "sh '''\n",
    "      echo \"==================================================\"\n",
    "      echo \"========--- SAST - Fortify Scan: Start ---========\"\n",
    "      echo \"==================================================\"\n",
    "      hostname\n",
    "      whoami\n",
    "      ls -ahl\n",
    "      echo 'WORKSPACE: ' $WORKSPACE\n",
    "      cd $WORKSPACE\n",
    "      pwd\n",
    "      sourceanalyzer -v\n",
    "      sourceanalyzer -b ${fortify_app_name} -clean\n",
    "      sourceanalyzer -b ${fortify_app_name} -python-version ${python_version} -python-path ${python_path} ${fortify_scan_files}\n",
    "      sourceanalyzer -b ${fortify_app_name} -scan -f ${fortify_app_name}.fpr\n",
    "      fortifyclient -url https://sast.intranet.asia/ssc -authtoken \"${fortify_upload_token}\" uploadFPR -file ${fortify_app_name}.fpr -project ${fortify_app_name} -version ${fortify_app_version}\n",
    "     '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Docker\n",
    "\n",
    "The next step is to build the docker image. We first login to Artifactory before initiating the build as our pip libraries are also pulled from mirrored pip in the Artifactory. I have provided a sample of code on how we achieve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-b4a310bd01e3>, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-b4a310bd01e3>\"\u001b[0;36m, line \u001b[0;32m15\u001b[0m\n\u001b[0;31m    \"\"\"\u001b[0m\n\u001b[0m       \n^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#hide_output\n",
    "sh \"\"\"\n",
    "                echo ${ARTIFACTORY_PASSWORD} | docker login -u ${ARTIFACTORY_USERNAME} --password-stdin docker-registry:8443\n",
    "                cd generator\n",
    "                docker build --file Docker-dev \\\n",
    "                 --build-arg HTTPS_PROXY=http://ip-address \\\n",
    "                 --build-arg ARTIFACTORY_USERNAME=${ARTIFACTORY_USERNAME} \\\n",
    "                 --build-arg ARTIFACTORY_PASSWORD=${ARTIFACTORY_PASSWORD} \\\n",
    "                 -t ${env.generator_image_latest} .\n",
    "                docker tag ${env.generator_image_latest} ${env.generator_image_name}\n",
    "                docker push ${env.generator_image_latest}\n",
    "                docker push ${env.generator_image_name}\n",
    "                docker logout docker-pcaaicoe.pruregistry.intranet.asia:8443\n",
    "                cd ..\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - Aquasec\n",
    "\n",
    "After pushing an image into Artifactory, the next important and mandatory step to be performed is docker image security scanning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-c8af31814524>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-c8af31814524>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    \"\"\"\u001b[0m\n\u001b[0m       \n^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#hide_output\n",
    "    sh \"\"\"\n",
    "         echo \"==================================================\"\n",
    "         echo \"=============--- OSS - Nexus Scan ---=============\"\n",
    "         echo \"==================================================\"\n",
    "                docker save -o generator-dev.tar ${env.generator_image_latest}\n",
    "                \"\"\"\n",
    "                String result = nexusscan(\"pcaaicoeaipulsenudgesgeneratordev\", \"$WORKSPACE\", \"build\");\n",
    "                echo result;\n",
    "                sh \"\"\"\n",
    "                rm -f generator-dev.tar\n",
    "                \"\"\"\n",
    "                sh \"\"\"\n",
    "                echo \"==================================================\"\n",
    "                echo \"=============--- CSEC - Aquasec Scan ---==========\"\n",
    "                echo \"==================================================\"\n",
    "    \"\"\"\n",
    "                aquasecscan(\"${env.generator_image_latest}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code and image security scanning stages are major milestones to be cleared during the deployment phase. It is important as well as difficult to explain and agree between application security teams about what risks are we willing to take while allowing open source libraries with bugs to go live in our environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 — Kubernetes\n",
    "\n",
    "Now we move on to the stage where we will be able to actually deploy and run our images. In order to deploy our solution, we need a Redis DB and Kafka cluster up and running. We deploy our docker images using the below code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-5e40e7794776>, line 89)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-5e40e7794776>\"\u001b[0;36m, line \u001b[0;32m89\u001b[0m\n\u001b[0;31m    '''\u001b[0m\n\u001b[0m       \n^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#hide_output\n",
    "sh '''\n",
    "            set +x\n",
    "            echo \"---- preparing options ----\"\n",
    "            export HTTPS_PROXY=ip-address:8080\n",
    "            export KUBE_NAMESPACE=\"internal-namespace\"\n",
    "            export KC_OPTS=${KC_OPTS}\" --kubeconfig=${KUBE_CONFIG}\"\n",
    "            export KC_OPTS=${KC_OPTS}\" --insecure-skip-tls-verify=true\"\n",
    "            export KC_OPTS=${KC_OPTS}\" --namespace=${KUBE_NAMESPACE}\"\n",
    "            \n",
    "            echo \"---- prepared options ----\"\n",
    "            echo \"---- preparing alias ----\"\n",
    "            alias kc=\"kubectl ${KC_OPTS} $*\"\n",
    "            echo \"---- alias prepared ----\"\n",
    "            \n",
    "            echo \"---- applying manifest ----\"\n",
    "   \n",
    "   \n",
    "           kc apply -f configmap.yaml\n",
    "\n",
    "           if [ $which_app = \"generator\" ];then\n",
    "             if [ $image_version = \"latest\" ];then\n",
    "               kc delete deploy ai-pulse-nudges-events-reader||echo\n",
    "             fi\n",
    "             sed -i \"s!GENERATOR_VERSION!$image_version!g\" \"generator.yaml\"\n",
    "             kc apply -f generator.yaml\n",
    "           fi  \n",
    "\n",
    "           if [ $which_app = \"aggregator\" ];then\n",
    "             if [ $image_version = \"latest\" ];then\n",
    "               kc delete deploy ai-pulse-nudges-click-counter||echo\n",
    "             fi\n",
    "             sed -i \"s!AGGREGATOR_VERSION!$image_version!g\" \"aggregator.yaml\"\n",
    "             kc apply -f aggregator.yaml\n",
    "           fi\n",
    "\n",
    "           if [ $which_app = \"detector\" ];then\n",
    "             if [ $image_version = \"latest\" ];then\n",
    "               kc delete deploy ai-pulse-nudges-engine||echo\n",
    "             fi\n",
    "             sed -i \"s!DETECTOR_VERSION!$image_version!g\" \"detector.yaml\" \n",
    "             kc apply -f detector.yaml\n",
    "           fi\n",
    "\n",
    "           if [ $which_app = \"restapi\" ];then\n",
    "             if [ $image_version = \"latest\" ];then\n",
    "               kc delete deploy ai-pulse-nudges-restapi||echo\n",
    "                fi\n",
    "             sed -i \"s!REST_VERSION!$image_version!g\" \"restapi.yaml\"\n",
    "             kc apply -f restapi.yaml\n",
    "                    fi\n",
    "            if [ $which_app = \"all\" ];then\n",
    "             if [ $image_version = \"latest\" ];then\n",
    "             kc delete deploy ai-pulse-nudges-events-reader||echo\n",
    "             kc delete deploy ai-pulse-nudges-click-counter||echo\n",
    "             kc delete deploy ai-pulse-nudges-engine||echo\n",
    "             kc delete deploy ai-pulse-nudges-restapi||echo\n",
    "             fi\n",
    "\n",
    "             sed -i \"s!GENERATOR_VERSION!$image_version!g\" \"generator.yaml\"\n",
    "             sed -i \"s!AGGREGATOR_VERSION!$image_version!g\" \"aggregator.yaml\"\n",
    "             sed -i \"s!DETECTOR_VERSION!$image_version!g\" \"detector.yaml\" \n",
    "             sed -i \"s!REST_VERSION!$image_version!g\" \"restapi.yaml\"\n",
    "\n",
    "             kc apply -f generator.yaml\n",
    "             kc apply -f aggregator.yaml\n",
    "             kc apply -f detector.yaml\n",
    "             kc apply -f restapi.yaml\n",
    "                    fi\n",
    "   \n",
    "   \n",
    "   \n",
    "            echo \"---- manifest applied ----\"\n",
    "            echo \"---- checking result ----\"\n",
    "            \n",
    "            echo \" >> Deployments \"\n",
    "            kc get deployments\n",
    "            \n",
    "            echo \" >> Services\"\n",
    "            kc get svc\n",
    "            \n",
    "            echo \" >> Ingress\"\n",
    "            kc get ingress\n",
    "            \n",
    "            echo \" >> Pods\"\n",
    "            kc get pods\n",
    "            \n",
    "            echo \"---- Done ----\"\n",
    "          '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6 — Performance test\n",
    "\n",
    "We deploy Predator — the tool which we use for performance test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
